{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import PIL\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = 'laion2b_s34b_b79k'\n",
    "path_image_tensors = '../real_images_artstation_filtered' + '_' + pretrained_model + '_ViT-B-32.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "from open_clip import tokenizer\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained=pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (patchnorm_pre_ln): Identity()\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_torch = torch.load(path_image_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7031, 3)\n"
     ]
    }
   ],
   "source": [
    "# read csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../real_images_artstation_filtered.csv')\n",
    "df.head()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = df['artist'].unique()\n",
    "text_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for artist in artists:\n",
    "        prompt = \"The following work is done in the style of \" + artist\n",
    "        text_tokens = tokenizer.tokenize(prompt)\n",
    "        text_tokens = text_tokens.to(device)\n",
    "        txt_feat = model.encode_text(text_tokens).float()\n",
    "        text_features.append(txt_feat)\n",
    "text_features_torch = torch.concatenate(text_features).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2artist = {}\n",
    "artist2idx = {}\n",
    "for i, artist in enumerate(artists):\n",
    "    idx2artist[i] = artist\n",
    "    artist2idx[artist] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_torch /= image_features_torch.norm(dim=-1, keepdim=True)\n",
    "text_features_torch /= text_features_torch.norm(dim=-1, keepdim=True)\n",
    "\n",
    "text_probs = (100.0 * image_features_torch @ text_features_torch.T).softmax(dim=-1)\n",
    "top_probs, top_k_labels = text_probs.cpu().topk(5, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7031]) torch.Size([7031])\n",
      "Top 1 score is 3.68\n",
      "Top 5 score is 8.01\n"
     ]
    }
   ],
   "source": [
    "gt_labels = torch.tensor([artist2idx[x] for x in df['artist'].to_list()])\n",
    "\n",
    "top_one_labels = top_k_labels[:, 0]\n",
    "\n",
    "print(gt_labels.shape, top_one_labels.shape)\n",
    "\n",
    "correct = (gt_labels == top_one_labels).sum()\n",
    "print(f\"Top 1 score is {round((correct / gt_labels.shape[0]).item() * 100, 2)}\")\n",
    "\n",
    "\n",
    "topk_correct = 0\n",
    "for i in range(5):\n",
    "    top_one_labels = top_k_labels[:, i]\n",
    "    correct = (gt_labels == top_one_labels).sum()\n",
    "    topk_correct += correct\n",
    "print(f\"Top 5 score is {round((topk_correct / gt_labels.shape[0]).item() * 100, 2)}\")\n",
    "# correct = (gt_labels.repeat() == top_k_labels).sum()\n",
    "# print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WLOP': 3.4482758620689653, 'Dao Trong Le': 0.0, 'Zeronis': 0.0, 'Chengwei Pan': 0.0, 'Wenjun Lin': 0.0, 'Grafit Studio': 0.0, 'Sylvain Sarrailh': 6.666666666666667, 'Greg Rutkowski': 0.0, 'Bayard Wu': 0.0, 'Bo Chen': 0.0, 'Tooth Wu': 0.0, 'Anato Finnstark': 0.0, 'Qi Sheng Luo': 0.0, 'Raf Grassetti': 0.0, 'sparth': 3.3333333333333335, 'Hicham Habchi': 0.0, 'Zhelong Xu': 0.0, 'Anthony Chong Jones': 0.0, 'Rudy Siswanto': 0.0, 'Nurzhan Bekkaliyev': 0.0, 'Jama Jurabaev': 0.0, 'Evan Lee': 0.0, 'Anatomy For Sculptors': 0.0, 'Christophe Young': 0.0, 'Eytan Zana': 0.0, 'Darek Zabrocki': 0.0, 'Jakub Rozalski': 0.0, 'Maria Panfilova': 0.0, 'Hou China': 0.0, 'Ismail Inceoglu': 3.3333333333333335, 'Andreas Rocha': 10.0, 'Johnson Ting': 0.0, 'Ching Yeh': 0.0, 'Paul Chadeisson': 3.3333333333333335, 'Igor Sid': 0.0, 'Jonas Ronnegard': 0.0, 'Nivanh Chanthara': 0.0, 'Thomas Chamberlain-Keen': 0.0, 'Steve Zheng': 0.0, 'Hue Teo': 0.0, 'Mauro Belfiore': 0.0, 'Raphael Lacoste': 3.3333333333333335, 'Dave Greco': 0.0, 'Dominik Mayer': 0.0, 'Tyler Smith': 0.0, 'Alena Aenami': 6.666666666666667, 'Anna Podedworna': 0.0, 'Hua Lu': 0.0, 'Eddie Mendoza': 0.0, 'Erak note': 0.0, 'Jessica Oyhenart': 13.333333333333334, 'Vitaly Bulgarov': 3.3333333333333335, 'Romain Jouandeau': 3.3333333333333335, 'florent lebrun': 0.0, 'richard anderson. flaptraps art studio': 3.3333333333333335, 'Sin jong hun': 0.0, 'Victor Titov': 0.0, 'Marco Plouffe (Keos Masons)': 0.0, 'Martin Deschambault': 0.0, 'SIXMOREVODKA STUDIO': 0.0, 'Jason Scheier': 0.0, 'Brian Sum': 0.0, 'Lorenzo Lanfranconi': 0.0, 'Oleg Vdovenko': 0.0, 'Siwoo Kim': 0.0, 'Wadim Kashin': 0.0, 'Anton Fadeev': 6.666666666666667, 'Sebastian Luca': 0.0, 'keita okada': 0.0, 'Russell Dongjun Lu': 0.0, 'Matt Rhodes': 0.0, 'seunghee lee': 3.3333333333333335, 'kleinerHai': 0.0, 'Wangjie Li': 0.0, 'Igor Artyomenko': 0.0, 'Valentina Remenar': 0.0, 'LiXin Yin': 0.0, 'Entei Ryu': 0.0, 'Finnian MacManus': 0.0, 'Grace Liu': 0.0, 'Justin Gerard': 0.0, 'Richard Wright': 0.0, 'Darren Bartley - fightPUNCH': 0.0, 'BASTIEN LECOUFFE DEHARME': 3.3333333333333335, 'Yuhong Ding': 0.0, 'Amir Zand': 0.0, 'Gabriel Soares': 0.0, 'adrian smith': 0.0, 'Kael Ngu': 3.3333333333333335, 'Gui Guimaraes': 0.0, 'John Wallin Liberto': 0.0, 'Pengzhen Zhang': 0.0, 'beeple': 3.3333333333333335, 'Qiu Fang': 0.0, 'Daniel Thiger': 0.0, 'Antonio J. Manzanedo': 0.0, 'Bach Do': 0.0, 'Tea Me': 0.0, 'Naranbaatar Ganbold': 0.0, 'Ina Wong': 0.0, 'Jakub Rebelka': 0.0, 'giorgio baroni': 0.0, 'Ivan Laliashvili': 0.0, 'Andrew Averkin': 0.0, 'Michal Kus': 0.0, 'Donglu Yu': 0.0, 'Yintion J - Jiang Geping': 0.0, 'Quentin Mabille': 0.0, 'Bastien Grivet': 0.0, 'lius lasahido': 0.0, 'Alexandre Chaudret': 0.0, 'DOFRESH .': 0.0, 'Alexander Mandradjiev': 0.0, 'mike franchina': 0.0, 'Maxim Verehin': 7.142857142857142, 'Huang Fan': 0.0, 'Max Bedulenko': 0.0, 'Mandy Jurgens': 0.0, 'Qifeng Lin': 0.0, 'Dylan Kowalski': 0.0, 'Jeff Simpson': 0.0, 'Khyzyl Saleem': 0.0, 'Song Nan Li': 0.0, 'Leon Tukker': 0.0, 'Airborn Studios': 0.0, 'Maarten Verhoeven': 0.0, 'Riccardo Federici': 0.0, 'ibrahem swaid': 0.0, 'Zeen Chin': 0.0, 'Ruan Jia': 0.0, 'Krenz Cushart': 6.666666666666667, 'Z.W. Gu': 0.0, 'TB Choi': 0.0, 'sakimi chan': 3.571428571428571, 'Kyoung Hwan Kim': 0.0, 'yang qi917': 0.0, 'Ilya Kuvshinov': 3.571428571428571, 'InHyuk Lee': 0.0, 'Sangsoo Jeong': 0.0, 'Rui Li': 3.3333333333333335, 'wonbin lee': 0.0, 'G liulian': 0.0, 'Sergey Kolesov': 0.0, 'su jian': 0.0, 'Yun Ling': 0.0, 'lovecacao': 0.0, 'Alex Flores': 0.0, 'Sean Tay': 0.0, 'Hong SoonSang': 3.3333333333333335, 'Nesskain HKS': 0.0, 'Wojtek Fus': 0.0, 'Jennifer Wuestling': 0.0, 'WenXu Xu': 0.0, 'Alexis Rives': 0.0, 'Citemer Liu': 6.666666666666667, 'M4 Miv4t': 0.0, 'Nicholas Kole': 0.0, 'Yizheng Ke': 0.0, 'Taejune Kim': 10.0, 'TaeKwon Kim': 0.0, 'Joon Ahn': 3.3333333333333335, 'Will Murai': 0.0, 'Jeehyung Lee': 0.0, 'J.Won Han': 0.0, 'Alejandro Burdisio': 0.0, 'Daeho Cha': 0.0, 'Huang Guangjian': 0.0, 'Insist': 0.0, 'KyuYong Eom': 0.0, 'Fenghua Zhong': 0.0, 'hyeonsick choi (aruana sick)': 13.333333333333334, 'CrazyJN': 3.3333333333333335, 'Jason Chan': 6.666666666666667, 'Pablo Dominguez': 0.0, 'mist XG': 0.0, 'Peter Mohrbacher': 3.3333333333333335, 'Amber Ye': 0.0, 'Satoshi Matsuura': 0.0, 'Johannes Helgeson': 0.0, 'Liang xing ( Jason Liang )': 0.0, 'Cedric Peyravernay': 3.3333333333333335, 'Stepan Alekseev': 0.0, 'Tan Zhi Hui': 0.0, 'STAR CG': 0.0, 'terry wei': 0.0, 'Xiaoyu Wang': 0.0, 'zhihui Su': 0.0, 'Chun Lo': 0.0, 'Paperblue': 0.0, '_Z eD_': 0.0, 'Artem Chebokha': 0.0, 'Toraji': 0.0, 'Xu Tianhua': 0.0, 'Vyacheslav Safronov': 0.0, 'Mirco Cabbia (Sciamano240)': 0.0, 'Irakli Nadar': 6.666666666666667, 'Hossein Diba': 3.3333333333333335, 'sang delan': 0.0, 'Serge Birault': 0.0, 'Alex Konstad': 0.0, 'lok du': 0.0, 'Xi Zhang': 0.0, 'Olya Anufrieva': 0.0, 'Nikolai Lockertsen': 0.0, 'Faraz Shanyar': 0.0, 'Ruxing Gao': 0.0, 'Rinotuna': 10.0, 'Mam BA': 0.0, 'MWARTOVA': 0.0, 'Seung Eun Kim': 0.0, 'Aleriia_V (lerapi)': 0.0, 'Bo Xun Lin': 0.0, 'Baldi Konijn': 0.0, 'Ya lun': 0.0, 'Swang .': 0.0, 'Sung Choi': 0.0, 'Nick Gindraux': 0.0, 'Gop Gap': 0.0, 'BangkuART': 0.0, 'Michal Lisowski': 3.3333333333333335, 'Pablo Carpio': 0.0, 'Liang Mark': 0.0, 'Nicola Saviori': 0.0, 'Kittew': 0.0, 'Rostyslav Zagornov': 0.0, 'Slawek Fedorczuk': 0.0, 'JiHun Lee': 0.0, 'Hui Zou': 0.0, 'jungmin jin /dospi': 0.0, 'Jeremy chong': 0.0, 'Zumi Draws': 0.0, 'Peter Xiao': 0.0, 'c home': 0.0, 'Betty Jiang': 0.0, 'Ren Wei Pan': 0.0, 'Jesper Ejsing': 0.0, 'Aoi Ogata': 6.666666666666667, 'Chocofing R': 0.0, 'JC Jongwon Park': 0.0, 'Mikhail Rakhmatullin': 0.0, 'Aleksandr Nikonov': 0.0, 'YU YIMING': 0.0, 'Samuel Smith': 0.0, 'Ian Spriggs': 0.0, 'Lin Chang': 0.0, 'John Grello': 0.0, 'N I X E U': 3.4482758620689653}\n"
     ]
    }
   ],
   "source": [
    "#compute the artist accuracy\n",
    "artist_accuracy = {}\n",
    "for i in range(len(artists)):\n",
    "    artist_accuracy[artists[i]] = 0\n",
    "for i in range(len(gt_labels)):\n",
    "    if gt_labels[i] == top_one_labels[i]:\n",
    "        artist_accuracy[artists[gt_labels[i]]] += 1\n",
    "for i in range(len(artists)):\n",
    "    artist_accuracy[artists[i]] /= len(df[df['artist'] == artists[i]])\n",
    "    #multiply by 100 to get percentage\n",
    "    artist_accuracy[artists[i]] *= 100\n",
    "print(artist_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jessica Oyhenart', 13.333333333333334), ('hyeonsick choi (aruana sick)', 13.333333333333334), ('Andreas Rocha', 10.0), ('Taejune Kim', 10.0), ('Rinotuna', 10.0), ('Maxim Verehin', 7.142857142857142), ('Sylvain Sarrailh', 6.666666666666667), ('Alena Aenami', 6.666666666666667), ('Anton Fadeev', 6.666666666666667), ('Krenz Cushart', 6.666666666666667), ('Citemer Liu', 6.666666666666667), ('Jason Chan', 6.666666666666667), ('Irakli Nadar', 6.666666666666667), ('Aoi Ogata', 6.666666666666667), ('sakimi chan', 3.571428571428571), ('Ilya Kuvshinov', 3.571428571428571), ('WLOP', 3.4482758620689653), ('N I X E U', 3.4482758620689653), ('sparth', 3.3333333333333335), ('Ismail Inceoglu', 3.3333333333333335), ('Paul Chadeisson', 3.3333333333333335), ('Raphael Lacoste', 3.3333333333333335), ('Vitaly Bulgarov', 3.3333333333333335), ('Romain Jouandeau', 3.3333333333333335), ('richard anderson. flaptraps art studio', 3.3333333333333335), ('seunghee lee', 3.3333333333333335), ('BASTIEN LECOUFFE DEHARME', 3.3333333333333335), ('Kael Ngu', 3.3333333333333335), ('beeple', 3.3333333333333335), ('Rui Li', 3.3333333333333335), ('Hong SoonSang', 3.3333333333333335), ('Joon Ahn', 3.3333333333333335), ('CrazyJN', 3.3333333333333335), ('Peter Mohrbacher', 3.3333333333333335), ('Cedric Peyravernay', 3.3333333333333335), ('Hossein Diba', 3.3333333333333335), ('Michal Lisowski', 3.3333333333333335), ('Dao Trong Le', 0.0), ('Zeronis', 0.0), ('Chengwei Pan', 0.0), ('Wenjun Lin', 0.0), ('Grafit Studio', 0.0), ('Greg Rutkowski', 0.0), ('Bayard Wu', 0.0), ('Bo Chen', 0.0), ('Tooth Wu', 0.0), ('Anato Finnstark', 0.0), ('Qi Sheng Luo', 0.0), ('Raf Grassetti', 0.0), ('Hicham Habchi', 0.0), ('Zhelong Xu', 0.0), ('Anthony Chong Jones', 0.0), ('Rudy Siswanto', 0.0), ('Nurzhan Bekkaliyev', 0.0), ('Jama Jurabaev', 0.0), ('Evan Lee', 0.0), ('Anatomy For Sculptors', 0.0), ('Christophe Young', 0.0), ('Eytan Zana', 0.0), ('Darek Zabrocki', 0.0), ('Jakub Rozalski', 0.0), ('Maria Panfilova', 0.0), ('Hou China', 0.0), ('Johnson Ting', 0.0), ('Ching Yeh', 0.0), ('Igor Sid', 0.0), ('Jonas Ronnegard', 0.0), ('Nivanh Chanthara', 0.0), ('Thomas Chamberlain-Keen', 0.0), ('Steve Zheng', 0.0), ('Hue Teo', 0.0), ('Mauro Belfiore', 0.0), ('Dave Greco', 0.0), ('Dominik Mayer', 0.0), ('Tyler Smith', 0.0), ('Anna Podedworna', 0.0), ('Hua Lu', 0.0), ('Eddie Mendoza', 0.0), ('Erak note', 0.0), ('florent lebrun', 0.0), ('Sin jong hun', 0.0), ('Victor Titov', 0.0), ('Marco Plouffe (Keos Masons)', 0.0), ('Martin Deschambault', 0.0), ('SIXMOREVODKA STUDIO', 0.0), ('Jason Scheier', 0.0), ('Brian Sum', 0.0), ('Lorenzo Lanfranconi', 0.0), ('Oleg Vdovenko', 0.0), ('Siwoo Kim', 0.0), ('Wadim Kashin', 0.0), ('Sebastian Luca', 0.0), ('keita okada', 0.0), ('Russell Dongjun Lu', 0.0), ('Matt Rhodes', 0.0), ('kleinerHai', 0.0), ('Wangjie Li', 0.0), ('Igor Artyomenko', 0.0), ('Valentina Remenar', 0.0), ('LiXin Yin', 0.0), ('Entei Ryu', 0.0), ('Finnian MacManus', 0.0), ('Grace Liu', 0.0), ('Justin Gerard', 0.0), ('Richard Wright', 0.0), ('Darren Bartley - fightPUNCH', 0.0), ('Yuhong Ding', 0.0), ('Amir Zand', 0.0), ('Gabriel Soares', 0.0), ('adrian smith', 0.0), ('Gui Guimaraes', 0.0), ('John Wallin Liberto', 0.0), ('Pengzhen Zhang', 0.0), ('Qiu Fang', 0.0), ('Daniel Thiger', 0.0), ('Antonio J. Manzanedo', 0.0), ('Bach Do', 0.0), ('Tea Me', 0.0), ('Naranbaatar Ganbold', 0.0), ('Ina Wong', 0.0), ('Jakub Rebelka', 0.0), ('giorgio baroni', 0.0), ('Ivan Laliashvili', 0.0), ('Andrew Averkin', 0.0), ('Michal Kus', 0.0), ('Donglu Yu', 0.0), ('Yintion J - Jiang Geping', 0.0), ('Quentin Mabille', 0.0), ('Bastien Grivet', 0.0), ('lius lasahido', 0.0), ('Alexandre Chaudret', 0.0), ('DOFRESH .', 0.0), ('Alexander Mandradjiev', 0.0), ('mike franchina', 0.0), ('Huang Fan', 0.0), ('Max Bedulenko', 0.0), ('Mandy Jurgens', 0.0), ('Qifeng Lin', 0.0), ('Dylan Kowalski', 0.0), ('Jeff Simpson', 0.0), ('Khyzyl Saleem', 0.0), ('Song Nan Li', 0.0), ('Leon Tukker', 0.0), ('Airborn Studios', 0.0), ('Maarten Verhoeven', 0.0), ('Riccardo Federici', 0.0), ('ibrahem swaid', 0.0), ('Zeen Chin', 0.0), ('Ruan Jia', 0.0), ('Z.W. Gu', 0.0), ('TB Choi', 0.0), ('Kyoung Hwan Kim', 0.0), ('yang qi917', 0.0), ('InHyuk Lee', 0.0), ('Sangsoo Jeong', 0.0), ('wonbin lee', 0.0), ('G liulian', 0.0), ('Sergey Kolesov', 0.0), ('su jian', 0.0), ('Yun Ling', 0.0), ('lovecacao', 0.0), ('Alex Flores', 0.0), ('Sean Tay', 0.0), ('Nesskain HKS', 0.0), ('Wojtek Fus', 0.0), ('Jennifer Wuestling', 0.0), ('WenXu Xu', 0.0), ('Alexis Rives', 0.0), ('M4 Miv4t', 0.0), ('Nicholas Kole', 0.0), ('Yizheng Ke', 0.0), ('TaeKwon Kim', 0.0), ('Will Murai', 0.0), ('Jeehyung Lee', 0.0), ('J.Won Han', 0.0), ('Alejandro Burdisio', 0.0), ('Daeho Cha', 0.0), ('Huang Guangjian', 0.0), ('Insist', 0.0), ('KyuYong Eom', 0.0), ('Fenghua Zhong', 0.0), ('Pablo Dominguez', 0.0), ('mist XG', 0.0), ('Amber Ye', 0.0), ('Satoshi Matsuura', 0.0), ('Johannes Helgeson', 0.0), ('Liang xing ( Jason Liang )', 0.0), ('Stepan Alekseev', 0.0), ('Tan Zhi Hui', 0.0), ('STAR CG', 0.0), ('terry wei', 0.0), ('Xiaoyu Wang', 0.0), ('zhihui Su', 0.0), ('Chun Lo', 0.0), ('Paperblue', 0.0), ('_Z eD_', 0.0), ('Artem Chebokha', 0.0), ('Toraji', 0.0), ('Xu Tianhua', 0.0), ('Vyacheslav Safronov', 0.0), ('Mirco Cabbia (Sciamano240)', 0.0), ('sang delan', 0.0), ('Serge Birault', 0.0), ('Alex Konstad', 0.0), ('lok du', 0.0), ('Xi Zhang', 0.0), ('Olya Anufrieva', 0.0), ('Nikolai Lockertsen', 0.0), ('Faraz Shanyar', 0.0), ('Ruxing Gao', 0.0), ('Mam BA', 0.0), ('MWARTOVA', 0.0), ('Seung Eun Kim', 0.0), ('Aleriia_V (lerapi)', 0.0), ('Bo Xun Lin', 0.0), ('Baldi Konijn', 0.0), ('Ya lun', 0.0), ('Swang .', 0.0), ('Sung Choi', 0.0), ('Nick Gindraux', 0.0), ('Gop Gap', 0.0), ('BangkuART', 0.0), ('Pablo Carpio', 0.0), ('Liang Mark', 0.0), ('Nicola Saviori', 0.0), ('Kittew', 0.0), ('Rostyslav Zagornov', 0.0), ('Slawek Fedorczuk', 0.0), ('JiHun Lee', 0.0), ('Hui Zou', 0.0), ('jungmin jin /dospi', 0.0), ('Jeremy chong', 0.0), ('Zumi Draws', 0.0), ('Peter Xiao', 0.0), ('c home', 0.0), ('Betty Jiang', 0.0), ('Ren Wei Pan', 0.0), ('Jesper Ejsing', 0.0), ('Chocofing R', 0.0), ('JC Jongwon Park', 0.0), ('Mikhail Rakhmatullin', 0.0), ('Aleksandr Nikonov', 0.0), ('YU YIMING', 0.0), ('Samuel Smith', 0.0), ('Ian Spriggs', 0.0), ('Lin Chang', 0.0), ('John Grello', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "#sort\n",
    "sorted_accuracy = sorted(artist_accuracy.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "Jessica Oyhenart 13.33\n",
      "hyeonsick choi (aruana sick) 13.33\n",
      "Andreas Rocha 10.0\n",
      "Taejune Kim 10.0\n",
      "Rinotuna 10.0\n",
      "Maxim Verehin 7.14\n",
      "Sylvain Sarrailh 6.67\n",
      "Alena Aenami 6.67\n",
      "Anton Fadeev 6.67\n",
      "Krenz Cushart 6.67\n"
     ]
    }
   ],
   "source": [
    "#higher 10\n",
    "print(\"Top 10\")\n",
    "for name, value in sorted_accuracy[:10]:\n",
    "    print(name, round(value, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10\n",
      "|Jessica Oyhenart|13.33%|\n",
      "|hyeonsick choi (aruana sick)|13.33%|\n",
      "|Andreas Rocha|10.0%|\n",
      "|Taejune Kim|10.0%|\n",
      "|Rinotuna|10.0%|\n",
      "|Maxim Verehin|7.14%|\n",
      "|Sylvain Sarrailh|6.67%|\n",
      "|Alena Aenami|6.67%|\n",
      "|Anton Fadeev|6.67%|\n",
      "|Krenz Cushart|6.67%|\n"
     ]
    }
   ],
   "source": [
    "#higher 10\n",
    "print(\"Top 10\")\n",
    "for name, value in sorted_accuracy[:10]:\n",
    "    print('|'+name+'|' + str(round(value, 2))+'%|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(artist_accuracy, orient='index', columns=['accuracy'])\n",
    "df.to_csv('../error_analysis/artists_real_img_artstation_filtered_error_analysis_'+pretrained_model+'_ViT-B-32.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
